{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d9670e-2a2c-4bf1-a315-9796c6789dc9",
   "metadata": {},
   "source": [
    "# Test the full connected layer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cd7c3-db80-4fa9-9d89-4f801ad7d1ed",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd85d865-3548-45b8-bf17-c6cdb4234763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python built-in libraries\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56327e98-27db-4fcf-aa87-dde8512b87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the tensorflow log level\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f930e0a7-cbc7-4f7e-8fe6-d50a90e4dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f020f42a-6eed-4f9c-8e76-26f15f8fff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohter packages\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc5985-ee2c-44f0-9f07-68c483675b77",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f389f0-549e-4dba-94ae-b963afe7b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "DATA_FILE = \"./data/all_data.nc\"  # path to the file of the feature tensor\n",
    "FRACTIONS = (0.8, 0.1, 0.1)  # train, validation, test\n",
    "BATCH_SIZE = 128  # size of the batch\n",
    "BUFFER_SIZE = BATCH_SIZE * 4  # size of the shuffle buffer\n",
    "RANDOM_SEED = 42  # a seed for the random sampling\n",
    "THRESHOLD = 0.95\n",
    "# training\n",
    "LEARNING_RATE = 0.001  # starting learning rate\n",
    "BETA1 = 0.9  # decay 1\n",
    "BETA2 = 0.999  # decay 2\n",
    "EPOCHS = 200  # number of epochs\n",
    "# saving\n",
    "TIME_STAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # time stamp\n",
    "MODEL_NAME = \"C4D4\"  # name of the model\n",
    "SAVE_LOC = \"./data/models/{}_{}\".format(MODEL_NAME, TIME_STAMP)  # path to the folder to save the model\n",
    "LOG_LOC = \"./data/logs/fit/{}_{}\".format(MODEL_NAME, TIME_STAMP)  # path to the log, if you change this, you also need to change it in the run_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2daffc-3f88-42de-be0e-f614c6e017ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Obtain data\n",
    "\n",
    "The data is a 209 data point PDF. The label is a one-hot 2 dim vector. `10` means major phase >= threshold, `01` means major phase <= threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d9be3eb-7058-4857-8eea-1cbee6674efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load\n",
    "    ds = xr.open_dataset(DATA_FILE)\n",
    "    features = ds[\"G\"].values\n",
    "    # label the data by threshold\n",
    "    single = np.array([1, 0])\n",
    "    mulitple = np.array([0, 1])\n",
    "    labels = np.apply_along_axis(lambda tup: single if np.max(tup) >= THRESHOLD else mulitple, 1,  ds[\"fraction\"].values)\n",
    "    # shuffle\n",
    "    n = features.shape[0]\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    shuffled_idx = np.random.permutation(n)\n",
    "    features, labels = features[shuffled_idx], labels[shuffled_idx]\n",
    "    # split\n",
    "    f0, f1, f2 = FRACTIONS\n",
    "    i, j, k = round(f0 * n), round((f0 + f1) * n), round((f0 + f1 + f2) * n)\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((features[:i], labels[:i])).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    valid_data = tf.data.Dataset.from_tensor_slices((features[i:j], labels[i:j])).batch(BATCH_SIZE)\n",
    "    test_data = tf.data.Dataset.from_tensor_slices((features[j:k], labels[j:k])).batch(BATCH_SIZE)\n",
    "    # close dataset\n",
    "    ds.close()\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76111e4f-5ed3-4318-bee1-9595f8359e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66341557-8f2e-4edf-876e-015398a118ee",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "We use the logistric regression. It is a single layer with a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c9ea8fd-4674-47b1-b871-eec08a87b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(209,)))\n",
    "    model.add(keras.layers.Reshape((209, 1)))\n",
    "    model.add(keras.layers.Conv1D(32, 3, strides=1, activation='relu', padding=\"same\"))\n",
    "    model.add(keras.layers.Conv1D(32, 3, strides=1, activation='relu', padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Conv1D(64, 3, strides=1, activation='relu', padding=\"same\"))\n",
    "    model.add(keras.layers.Conv1D(64, 3, strides=1, activation='relu', padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "505c4f8e-4b54-4343-877f-8bd6485d7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ab9ec7a-e391-4912-b9df-659f295ca313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 209, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 209, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 209, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 209, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 104, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 104, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 104, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 52, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 52, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3328)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1704448   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,796,482\n",
      "Trainable params: 1,796,290\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668bbf47-4604-4388-bda2-f7d384b332ae",
   "metadata": {},
   "source": [
    "## Choose optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "541c52ba-2aa5-48d4-b40c-75d0948b3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(LEARNING_RATE, BETA1, BETA2),\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[\n",
    "        keras.metrics.CosineSimilarity(),\n",
    "        keras.metrics.CategoricalAccuracy()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d396f-3334-433d-99d9-d6026ab524d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2ac30aa-afc3-42c7-9f7c-0f057f1496d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor board\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_LOC, \n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9de9aa59-d48e-476c-8a18-f83a07ea1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping to avoid over fitting\n",
    "earlystopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ecfa6ce-8dd6-4ca9-aab9-d5008b5120b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "688/688 [==============================] - 26s 17ms/step - loss: 0.6426 - cosine_similarity: 0.7519 - categorical_accuracy: 0.6636 - val_loss: 0.5519 - val_cosine_similarity: 0.7901 - val_categorical_accuracy: 0.7235\n",
      "Epoch 2/200\n",
      "688/688 [==============================] - 11s 16ms/step - loss: 0.5265 - cosine_similarity: 0.8005 - categorical_accuracy: 0.7359 - val_loss: 0.4902 - val_cosine_similarity: 0.8180 - val_categorical_accuracy: 0.7618\n",
      "Epoch 3/200\n",
      "688/688 [==============================] - 11s 16ms/step - loss: 0.4619 - cosine_similarity: 0.8288 - categorical_accuracy: 0.7740 - val_loss: 0.4306 - val_cosine_similarity: 0.8445 - val_categorical_accuracy: 0.8014\n",
      "Epoch 4/200\n",
      "688/688 [==============================] - 11s 16ms/step - loss: 0.3994 - cosine_similarity: 0.8552 - categorical_accuracy: 0.8125 - val_loss: 0.4073 - val_cosine_similarity: 0.8543 - val_categorical_accuracy: 0.8108\n",
      "Epoch 5/200\n",
      "688/688 [==============================] - 12s 17ms/step - loss: 0.3573 - cosine_similarity: 0.8716 - categorical_accuracy: 0.8331 - val_loss: 0.3854 - val_cosine_similarity: 0.8643 - val_categorical_accuracy: 0.8271\n",
      "Epoch 6/200\n",
      "688/688 [==============================] - 13s 19ms/step - loss: 0.3197 - cosine_similarity: 0.8868 - categorical_accuracy: 0.8535 - val_loss: 0.3644 - val_cosine_similarity: 0.8736 - val_categorical_accuracy: 0.8395\n",
      "Epoch 7/200\n",
      "688/688 [==============================] - 12s 17ms/step - loss: 0.2913 - cosine_similarity: 0.8975 - categorical_accuracy: 0.8680 - val_loss: 0.3573 - val_cosine_similarity: 0.8797 - val_categorical_accuracy: 0.8497\n",
      "Epoch 8/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.2684 - cosine_similarity: 0.9065 - categorical_accuracy: 0.8810 - val_loss: 0.3510 - val_cosine_similarity: 0.8831 - val_categorical_accuracy: 0.8561\n",
      "Epoch 9/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.2493 - cosine_similarity: 0.9127 - categorical_accuracy: 0.8884 - val_loss: 0.3563 - val_cosine_similarity: 0.8870 - val_categorical_accuracy: 0.8620\n",
      "Epoch 10/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.2306 - cosine_similarity: 0.9202 - categorical_accuracy: 0.8993 - val_loss: 0.3604 - val_cosine_similarity: 0.8937 - val_categorical_accuracy: 0.8704\n",
      "Epoch 11/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.2102 - cosine_similarity: 0.9273 - categorical_accuracy: 0.9084 - val_loss: 0.3380 - val_cosine_similarity: 0.8990 - val_categorical_accuracy: 0.8760\n",
      "Epoch 12/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.2007 - cosine_similarity: 0.9310 - categorical_accuracy: 0.9130 - val_loss: 0.3534 - val_cosine_similarity: 0.8997 - val_categorical_accuracy: 0.8801\n",
      "Epoch 13/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1945 - cosine_similarity: 0.9335 - categorical_accuracy: 0.9162 - val_loss: 0.3571 - val_cosine_similarity: 0.8948 - val_categorical_accuracy: 0.8719\n",
      "Epoch 14/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1843 - cosine_similarity: 0.9369 - categorical_accuracy: 0.9195 - val_loss: 0.3472 - val_cosine_similarity: 0.9035 - val_categorical_accuracy: 0.8837\n",
      "Epoch 15/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1741 - cosine_similarity: 0.9405 - categorical_accuracy: 0.9250 - val_loss: 0.3419 - val_cosine_similarity: 0.9021 - val_categorical_accuracy: 0.8816\n",
      "Epoch 16/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1820 - cosine_similarity: 0.9372 - categorical_accuracy: 0.9221 - val_loss: 0.3414 - val_cosine_similarity: 0.9005 - val_categorical_accuracy: 0.8782\n",
      "Epoch 17/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1646 - cosine_similarity: 0.9444 - categorical_accuracy: 0.9301 - val_loss: 0.3571 - val_cosine_similarity: 0.8997 - val_categorical_accuracy: 0.8781\n",
      "Epoch 18/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1599 - cosine_similarity: 0.9453 - categorical_accuracy: 0.9310 - val_loss: 0.3821 - val_cosine_similarity: 0.8926 - val_categorical_accuracy: 0.8685\n",
      "Epoch 19/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1628 - cosine_similarity: 0.9441 - categorical_accuracy: 0.9296 - val_loss: 0.3830 - val_cosine_similarity: 0.8915 - val_categorical_accuracy: 0.8713\n",
      "Epoch 20/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1576 - cosine_similarity: 0.9464 - categorical_accuracy: 0.9324 - val_loss: 0.3599 - val_cosine_similarity: 0.9018 - val_categorical_accuracy: 0.8808\n",
      "Epoch 21/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1432 - cosine_similarity: 0.9517 - categorical_accuracy: 0.9398 - val_loss: 0.3729 - val_cosine_similarity: 0.9010 - val_categorical_accuracy: 0.8811\n",
      "Epoch 22/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1441 - cosine_similarity: 0.9511 - categorical_accuracy: 0.9388 - val_loss: 0.3742 - val_cosine_similarity: 0.8904 - val_categorical_accuracy: 0.8675\n",
      "Epoch 23/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1392 - cosine_similarity: 0.9527 - categorical_accuracy: 0.9405 - val_loss: 0.3919 - val_cosine_similarity: 0.9027 - val_categorical_accuracy: 0.8841\n",
      "Epoch 24/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1332 - cosine_similarity: 0.9552 - categorical_accuracy: 0.9441 - val_loss: 0.3632 - val_cosine_similarity: 0.9010 - val_categorical_accuracy: 0.8832\n",
      "Epoch 25/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1339 - cosine_similarity: 0.9551 - categorical_accuracy: 0.9444 - val_loss: 0.3731 - val_cosine_similarity: 0.9066 - val_categorical_accuracy: 0.8890\n",
      "Epoch 26/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1270 - cosine_similarity: 0.9571 - categorical_accuracy: 0.9463 - val_loss: 0.3807 - val_cosine_similarity: 0.9079 - val_categorical_accuracy: 0.8922\n",
      "Epoch 27/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1228 - cosine_similarity: 0.9586 - categorical_accuracy: 0.9480 - val_loss: 0.4279 - val_cosine_similarity: 0.8918 - val_categorical_accuracy: 0.8729\n",
      "Epoch 28/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1247 - cosine_similarity: 0.9587 - categorical_accuracy: 0.9488 - val_loss: 0.3622 - val_cosine_similarity: 0.9076 - val_categorical_accuracy: 0.8909\n",
      "Epoch 29/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1235 - cosine_similarity: 0.9587 - categorical_accuracy: 0.9483 - val_loss: 0.3712 - val_cosine_similarity: 0.9090 - val_categorical_accuracy: 0.8916\n",
      "Epoch 30/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1196 - cosine_similarity: 0.9600 - categorical_accuracy: 0.9506 - val_loss: 0.3680 - val_cosine_similarity: 0.9086 - val_categorical_accuracy: 0.8925\n",
      "Epoch 31/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1166 - cosine_similarity: 0.9615 - categorical_accuracy: 0.9524 - val_loss: 0.3529 - val_cosine_similarity: 0.9069 - val_categorical_accuracy: 0.8895\n",
      "Epoch 32/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1119 - cosine_similarity: 0.9626 - categorical_accuracy: 0.9546 - val_loss: 0.3850 - val_cosine_similarity: 0.9112 - val_categorical_accuracy: 0.8954\n",
      "Epoch 33/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1096 - cosine_similarity: 0.9634 - categorical_accuracy: 0.9544 - val_loss: 0.3896 - val_cosine_similarity: 0.9024 - val_categorical_accuracy: 0.8862\n",
      "Epoch 34/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1125 - cosine_similarity: 0.9626 - categorical_accuracy: 0.9534 - val_loss: 0.3618 - val_cosine_similarity: 0.9114 - val_categorical_accuracy: 0.8957\n",
      "Epoch 35/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1072 - cosine_similarity: 0.9647 - categorical_accuracy: 0.9565 - val_loss: 0.3897 - val_cosine_similarity: 0.9111 - val_categorical_accuracy: 0.8961\n",
      "Epoch 36/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1059 - cosine_similarity: 0.9644 - categorical_accuracy: 0.9556 - val_loss: 0.3874 - val_cosine_similarity: 0.9094 - val_categorical_accuracy: 0.8958\n",
      "Epoch 37/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1043 - cosine_similarity: 0.9651 - categorical_accuracy: 0.9562 - val_loss: 0.3653 - val_cosine_similarity: 0.9159 - val_categorical_accuracy: 0.9011\n",
      "Epoch 38/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1018 - cosine_similarity: 0.9665 - categorical_accuracy: 0.9586 - val_loss: 0.3327 - val_cosine_similarity: 0.9105 - val_categorical_accuracy: 0.8933\n",
      "Epoch 39/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.1041 - cosine_similarity: 0.9655 - categorical_accuracy: 0.9570 - val_loss: 0.3548 - val_cosine_similarity: 0.9122 - val_categorical_accuracy: 0.8971\n",
      "Epoch 40/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0977 - cosine_similarity: 0.9677 - categorical_accuracy: 0.9607 - val_loss: 0.3791 - val_cosine_similarity: 0.9146 - val_categorical_accuracy: 0.9020\n",
      "Epoch 41/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0984 - cosine_similarity: 0.9676 - categorical_accuracy: 0.9598 - val_loss: 0.3871 - val_cosine_similarity: 0.9126 - val_categorical_accuracy: 0.8982\n",
      "Epoch 42/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.1032 - cosine_similarity: 0.9660 - categorical_accuracy: 0.9584 - val_loss: 0.3784 - val_cosine_similarity: 0.9148 - val_categorical_accuracy: 0.9013\n",
      "Epoch 43/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0966 - cosine_similarity: 0.9680 - categorical_accuracy: 0.9604 - val_loss: 0.4195 - val_cosine_similarity: 0.8955 - val_categorical_accuracy: 0.8771\n",
      "Epoch 44/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0931 - cosine_similarity: 0.9692 - categorical_accuracy: 0.9620 - val_loss: 0.3892 - val_cosine_similarity: 0.9124 - val_categorical_accuracy: 0.8975\n",
      "Epoch 45/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0935 - cosine_similarity: 0.9696 - categorical_accuracy: 0.9629 - val_loss: 0.4463 - val_cosine_similarity: 0.9119 - val_categorical_accuracy: 0.8984\n",
      "Epoch 46/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0901 - cosine_similarity: 0.9702 - categorical_accuracy: 0.9629 - val_loss: 0.3710 - val_cosine_similarity: 0.9133 - val_categorical_accuracy: 0.8981\n",
      "Epoch 47/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0863 - cosine_similarity: 0.9714 - categorical_accuracy: 0.9647 - val_loss: 0.3760 - val_cosine_similarity: 0.9138 - val_categorical_accuracy: 0.9005\n",
      "Epoch 48/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0885 - cosine_similarity: 0.9710 - categorical_accuracy: 0.9640 - val_loss: 0.4162 - val_cosine_similarity: 0.9138 - val_categorical_accuracy: 0.9001\n",
      "Epoch 49/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0895 - cosine_similarity: 0.9706 - categorical_accuracy: 0.9637 - val_loss: 0.3637 - val_cosine_similarity: 0.9145 - val_categorical_accuracy: 0.9002\n",
      "Epoch 50/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0859 - cosine_similarity: 0.9721 - categorical_accuracy: 0.9660 - val_loss: 0.3739 - val_cosine_similarity: 0.9143 - val_categorical_accuracy: 0.9001\n",
      "Epoch 51/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0824 - cosine_similarity: 0.9729 - categorical_accuracy: 0.9670 - val_loss: 0.4014 - val_cosine_similarity: 0.9115 - val_categorical_accuracy: 0.8977\n",
      "Epoch 52/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0853 - cosine_similarity: 0.9718 - categorical_accuracy: 0.9651 - val_loss: 0.4061 - val_cosine_similarity: 0.9107 - val_categorical_accuracy: 0.8978\n",
      "Epoch 53/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0849 - cosine_similarity: 0.9727 - categorical_accuracy: 0.9665 - val_loss: 0.3967 - val_cosine_similarity: 0.9166 - val_categorical_accuracy: 0.9060\n",
      "Epoch 54/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0798 - cosine_similarity: 0.9737 - categorical_accuracy: 0.9677 - val_loss: 0.4109 - val_cosine_similarity: 0.9154 - val_categorical_accuracy: 0.9027\n",
      "Epoch 55/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0811 - cosine_similarity: 0.9736 - categorical_accuracy: 0.9674 - val_loss: 0.3729 - val_cosine_similarity: 0.9159 - val_categorical_accuracy: 0.9014\n",
      "Epoch 56/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0798 - cosine_similarity: 0.9736 - categorical_accuracy: 0.9673 - val_loss: 0.4064 - val_cosine_similarity: 0.9104 - val_categorical_accuracy: 0.8954\n",
      "Epoch 57/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0835 - cosine_similarity: 0.9725 - categorical_accuracy: 0.9662 - val_loss: 0.3652 - val_cosine_similarity: 0.9172 - val_categorical_accuracy: 0.9032\n",
      "Epoch 58/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0793 - cosine_similarity: 0.9743 - categorical_accuracy: 0.9688 - val_loss: 0.3804 - val_cosine_similarity: 0.9147 - val_categorical_accuracy: 0.9007\n",
      "Epoch 59/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0786 - cosine_similarity: 0.9744 - categorical_accuracy: 0.9679 - val_loss: 0.4034 - val_cosine_similarity: 0.9174 - val_categorical_accuracy: 0.9059\n",
      "Epoch 60/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0772 - cosine_similarity: 0.9749 - categorical_accuracy: 0.9695 - val_loss: 0.4213 - val_cosine_similarity: 0.9121 - val_categorical_accuracy: 0.8977\n",
      "Epoch 61/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0740 - cosine_similarity: 0.9759 - categorical_accuracy: 0.9701 - val_loss: 0.4329 - val_cosine_similarity: 0.9177 - val_categorical_accuracy: 0.9067\n",
      "Epoch 62/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0750 - cosine_similarity: 0.9759 - categorical_accuracy: 0.9707 - val_loss: 0.3783 - val_cosine_similarity: 0.9178 - val_categorical_accuracy: 0.9068\n",
      "Epoch 63/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0766 - cosine_similarity: 0.9746 - categorical_accuracy: 0.9683 - val_loss: 0.4242 - val_cosine_similarity: 0.9133 - val_categorical_accuracy: 0.8992\n",
      "Epoch 64/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0762 - cosine_similarity: 0.9750 - categorical_accuracy: 0.9685 - val_loss: 0.3992 - val_cosine_similarity: 0.9128 - val_categorical_accuracy: 0.8995\n",
      "Epoch 65/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0722 - cosine_similarity: 0.9766 - categorical_accuracy: 0.9712 - val_loss: 0.4608 - val_cosine_similarity: 0.9043 - val_categorical_accuracy: 0.8903\n",
      "Epoch 66/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0754 - cosine_similarity: 0.9755 - categorical_accuracy: 0.9701 - val_loss: 0.3993 - val_cosine_similarity: 0.9124 - val_categorical_accuracy: 0.8991\n",
      "Epoch 67/200\n",
      "688/688 [==============================] - 10s 14ms/step - loss: 0.0702 - cosine_similarity: 0.9771 - categorical_accuracy: 0.9713 - val_loss: 0.3931 - val_cosine_similarity: 0.9146 - val_categorical_accuracy: 0.9015\n",
      "Epoch 68/200\n",
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0699 - cosine_similarity: 0.9775 - categorical_accuracy: 0.9723 - val_loss: 0.3930 - val_cosine_similarity: 0.9120 - val_categorical_accuracy: 0.8959\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_data,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        earlystopping_callback\n",
    "    ],\n",
    "    validation_data=valid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177de451-f03a-495d-a09d-755626fce563",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d0f540d-a99b-405b-8d05-f138f55a95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 7ms/step - loss: 0.3279 - cosine_similarity: 0.9092 - categorical_accuracy: 0.8921\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(\n",
    "    x=test_data,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "296385b0-a5b1-43eb-9aa8-59c7e15a036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss                 0.3279\n",
      "cosine_similarity    0.9092\n",
      "categorical_accuracy 0.8921\n"
     ]
    }
   ],
   "source": [
    "for name, val in result.items():\n",
    "    print(\"{:20s} {:.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570cabab-3653-4151-a2a7-051680c25de8",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "416ba8a8-9e6d-4d5e-9685-e211f2f759f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/C4D4_20210928-190611/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(SAVE_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6370361-ae52-4e37-9c8a-3c76556ccb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:st3107-tfgpu] *",
   "language": "python",
   "name": "conda-env-st3107-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
